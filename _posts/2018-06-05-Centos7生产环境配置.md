---
layout:     post
title:      CentOS7生产环境搭建
subtitle:   CentOS7生产环境搭建(VNC;Java;IDE等)
date:       2018-06-05
author:     Alitria
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - CentOS7
    - Shell
---

## 安装图形化界面  

- 1.yum groupinstall GNOME Desktop
- 2.一路yes即可

## VNC搭建  

- 1.打开终端
- 2.yum install tigervnc tigervnc-server(一路yes即可)
- 3.cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service
- 4.vim /etc/systemd/system/vncserver@:1.service(将所有USER包含尖括号改成root)  
- 5.systemctl start vncserver@:1.service;systemctl enable vncserver@:1.service  
- 6.如果上一步遇到了错误(Job for vncserver@:1.service failed because the control process exited with error code. See 
"systemctl status vncserver@:1.service" and "journalctl -xe" for details.)。执行：rm -R /tmp/.X11-unix/后再执行第五步。
- 7.设置密码：vncpasswd，输入两次密码。
- 8.设置防火墙(选做)，第9、10步。
- 9.firewall-cmd --permanent --add-service="vnc-server" --zone="public"
- 10.firewall-cmd --reload
- 11.开启VNC：vncserver(或vncserver :1)
- 12.VNC-Viewer，输入ip:5901即可。

## 删除OpenJDK

- 1.切换到root账户
- 2.rqm -qa 管道竖线 grep java
- 3.rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64
- 4.rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64
- 5.rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64
- 6.rpm -e --nodeps java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64

## JDK配置

- 1.解压：tar xzvf jdk-8u144-linux-x64.tar.gz
- 2.vim /etc/profile
- 3.添加如下内容
- 4.export JAVA_HOME=/usr/java/jdk
- 5.export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
- 6.export PATH=$JAVA_HOME/bin:$PATH
- 7.source /etc/profile
- 8.验证：java -version


## IDEA配置

- 1.解压：tar xzvf ideaIU-2018.1.4.tar.gz
- 2.启动：sh idea.sh


## SCALA配置(2.11.12)

- 1.解压：tar -zxf scala-2.11.12.tgz
- 2.vim /etc/profile
- 3.添加如下内容
- 4.export SCALA_HOME=/usr/scala/scala-2.11.6
- 5.export PATH=$PATH:$SCALA_HOME/bin
- 6.source /etc/profile
- 7.验证：scala -version

## SPARK配置(1.6.2)

- 1.解压：tar -xzvf spark-1.6.2-bin-hadoop2.6.tgz
- 2.vim /etc/profile
- 3.添加如下内容
- 4.export SPARK_HOME=/usr/app/spark-1.6.0 
- 5.export PATH=$SPARK_HOME/bin:$PATH
- 6.source /etc/profile
- 7.转到/spark-1.6.2-bin-hadoop2.6/conf/下
- 8.执行：cp spark-env.sh.template spark-env.sh，并按下面修改内容(类似设置JDK),分号代表换行符
- 9.export SCALA_HOME=/mysoftware/scala-2.11.8;export JAVA_HOME=/mysoftware/jdk1.7.0_80;export SPARK_HOME=/home/ZHOU/SPARK;export SPARK_MASTER_IP=你的ip;export SPARK_WORKER_MEMORY=4G
- 10.执行：cp slaves.template slaves,最下面一行设置为：localhost
- 11.执行：cp log4j.properties.template log4j.properties,无需其他设置
- 12.测试Spark是否装好，在bin目录下执行：./run-example SparkPi 10，如果打印出"Pi is roughly 3.141852"，即说明成功。
- 13.启动：/sbin/start-all.sh
- 14.停止：/sbin/stop-all.sh

## HADOOP单机配置(2.6.0)

- 1.解压：tar zxvf hadoop-2.6.0.tar.gz
- 2.修改路径/hadoop-2.7.3/etc/hadoop的文件hadoop-env.sh，将JDK路径加进去(export JAVA_HOME=/home/ZHOU/jdk1.8)
- 3.配置Hadoop环境变量(export HADOOP_HOME=/usr/hadoop/hadoop-2.7.3; export PATH=$PATH:$HADOOP_HOME/bin)
- 4.执行：source /etc/profile
- 5.修改路径/hadoop-2.7.3/etc/hadoop的文件core-site.xml,如下  

![](http://ww1.sinaimg.cn/large/005L0VzSly1fs2o5egqi1j30ei07g0t4.jpg)  

- 6.修改路径/hadoop-2.7.3/etc/hadoop的文件hdfs-site.xml,如下  

![](http://ww1.sinaimg.cn/large/005L0VzSly1fs2o7l4vvtj30k708swf2.jpg)  

- 7.配置完成后，执行初始化：./bin/hdfs namenode -format，打印出的部分信息如下，其中这个127.0.0.1报的错我目前没搞懂啥意思，但是并不影响HDFS的启动  

```
15/05/13 08:50:15 INFO namenode.FSImage: Allocated new BlockPoolId: BP-707136192-127.0.1.1-1431532215593
15/05/13 08:50:15 INFO common.Storage: Storage directory /home/hadoop/opt/hadoop-2.6.0/tmp/dfs/name has been successfully formatted.
15/05/13 08:50:16 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
15/05/13 08:50:16 INFO util.ExitUtil: Exiting with status 0
15/05/13 08:50:16 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.1.1
************************************************************/
```  
  
  
- 8.开启HDFS(NameNode&DataNode):sbin/start-dfs.sh  

![](http://ww1.sinaimg.cn/large/005L0VzSgy1fs2odyrlodj309a042jrg.jpg)  

- 9.打开浏览器，输入：localhost：50070，可看到  

![](http://ww1.sinaimg.cn/large/005L0VzSgy1fs2ohru52ej30rz0cpmxp.jpg)  

- 10.关闭HDFS：sbin/stop-dfs.sh

## 集群环境下利用KVM分割多机配置静态ip

- 1. cd /etc/sysconfig/network-scripts
- 2. sudo vim ifcfg-eth0
- 3. 修改BOOTPROTO=static
- 4. 修改ONBOOT=yes
- 5. 添加IPADDR=(动态获取的ip)
- 6. 添加NETMASK=255.255.255.0
- 7. 添加GATEWAY=(宿主网关，在宿主机用netstat -rn查询)
- 8. 添加DNS1=114.114.114.114
- 9. 重启网络：service network start

## 多机间免密登陆

&emsp;&emsp;1.对每台主机修改主机名，主节点(master)，从节点(slaver0x)：sudo vim /etc/hostname  
&emsp;&emsp;2.对每台主机添加节点ip以及对应的主机名:sudo vim /etc/hosts 例如(10.1.18.1 master; 10.1.18.2 slaver01)  
&emsp;&emsp;3.对每台主机修改sshd配置文件：sudo vim /etc/ssh/sshd_config 将如下点亮(RSAAuthentication yes;PubkeyAuthentication yes;AuthorizedKeysFile      .ssh/authorized_keys)后重启ssh服务：service ssh restart  
&emsp;&emsp;4.对每台机器生成密钥：ssh-keygen -t rsa -p ""  
&emsp;&emsp;5.将所有机器的密钥(公共.pub)汇总到master，利用:cat xxx.pub >> authorized_keys 将各个节点公钥打入该文件  
&emsp;&emsp;6.利用scp命令分发authorized_keys文件到各个节点  
&emsp;&emsp;7.授权：sudo chmod 700 ~/.ssh; sudo chmod 644 ~/.ssh/authorized_keys; sudo chmod 644 ~/.ssh/known_hosts  
&emsp;&emsp;8.搞定  

## 多机间免密登陆故障处理

- 1.WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!本机ip:10.1.18.100,欲连接的ip:10.1.18.124,修改本机ip路径下/.ssh的文件konwn_hosts,将与欲连接的ip相关的内容删掉，重新ssh连接即可。

## HADOOP完全分布式配置(2.6.0)

&emsp;&emsp;1.登录root账户(su root);将压缩包上传至服务器的/usr下;并解压(tar xzvf hadoop2.6.0.......)  
&emsp;&emsp;2.重命名(mv hadoop2.6.0....... hadoop2.6.0); 授权(chown -R hadoop:hadoop hadoop2.6.0)  
&emsp;&emsp;3.添加环境变量(vim /etc/profile)  
```
export HADOOP_HOME=/usr/hadoop2.6.0
export PATH=$PATH:$HADOOP_HOME/bin
```
&emsp;&emsp;4.配置Hadoop文件  
&emsp;&emsp;4.1./etc/hadoop/hadoop-env.sh  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1am5snfkj308c01e0sj.jpg)  

&emsp;&emsp;4.2./etc/hadoop/yarn-env.sh  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1an9ujvhj308x032glh.jpg)  

&emsp;&emsp;4.3./etc/hadoop/slaves  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1annl330j303x020dfl.jpg)  

&emsp;&emsp;4.4./etc/hadoop/core-site.xml  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1aodfwuoj30eg08cmx9.jpg)  

&emsp;&emsp;4.5./etc/hadoop/hdfs-site.xml  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1aop7jz5j30ed08eglq.jpg)

&emsp;&emsp;4.6./etc/hadoop/mapred-site.xml  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1apg4hm3j30ei06o0ss.jpg)  

&emsp;&emsp;4.7./etc/hadoop/yarn-site.xml  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1aqpu307j30io0fy758.jpg)

&emsp;&emsp;5.格式化namenode(hdfs namenode -format)ps:主节点机器重启后可能需要重新格式化namenode  

&emsp;&emsp;6.启动:start-all.sh;start-dfs.sh;start-yarn.sh  

&emsp;&emsp;7.结果查询，在各个机器上使用jps命令即可

&emsp;&emsp;8.结果截图  

&emsp;&emsp;8.1.master:  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1b3ib1hmj305v032744.jpg)  

&emsp;&emsp;8.2.slaver0x:  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1b3v2y7jj305y02j3yb.jpg)  

&emsp;&emsp;8.3.打开火狐浏览器，输入:master:50070;master:8088;slaves:8042 


## Spark完全分布式配置(1.6.2)

&emsp;&emsp;1.首先关闭各个机器的防火墙，最好是开机禁用firewall(systemctl stop firewalld.service #停止firewall; systemctl disable firewalld.service #禁止firewall开机启动)  

&emsp;&emsp;2.在各台机器上先配置Scala环境(参考前面单机即可)  

&emsp;&emsp;3.在各台机器上解压缩(tar -zxvf spark-xxx.tgz)  

&emsp;&emsp;4.在各台机器上改名(mv spark-xxx.tgz spark1.6.2)  

&emsp;&emsp;5.在各台机器上配环境变量  
```
vim /etc/profile

export SPARK_HOME=/usr/spark1.6.2
export PATH=$PATH:$SPARK_HOME/bin
```

&emsp;&emsp;6.在各台机器上修改conf/spark-env.sh, 如下  

```
export JAVA_HOME=/usr/java/jdk1.8.0_141
 
export SCALA_HOME=/usr/scala-2.11.7
 
export HADOOP_HOME=/opt/hadoop-2.6.5
 
export HADOOP_CONF_DIR=/usr/hadoop2.6.0/etc/hadoop
 
export SPARK_MASTER_IP=10.1.18.125

export SPARK_MASTER_PORT=7077

export SPARK_MASTER_HOST=10.1.18.125

export SPARK_WORKER_MEMORY=2g
 
export SPARK_WORKER_CORES=2
 
export SPARK_WORKER_INSTANCES=1
```
&emsp;&emsp;PS:master_ip必须填真实ip，不能用master代替  

&emsp;&emsp;7.在各台机器上修改conf/slaves, 如下 

```
salver01
slaver02
slaver03
```
&emsp;&emsp;8.启动Spark(必须cd到/spark1.6.0/sbin目录下执行sh ./start-all.sh)  

&emsp;&emsp;9.验证安装成果(各个机器上jps一下; 在浏览器上输入master:8080回车查看)  






