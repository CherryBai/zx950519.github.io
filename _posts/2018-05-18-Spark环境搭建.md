---
layout:     post
title:      Spark环境——Win10安装&配置
subtitle:   Spark环境配置
date:       2018-05-18
author:     Alitria
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Spark
    - 开发环境
    - Cmd
---
## 声明：此环境是在Win10下验证安装，Win系列均可参照配置！

## 环境准备
- Jdk(1.8+)安装与配置
- Scala(2.16.2)安装与配置
- Spark(2.3.0)安装与配置
- Hadoop(2.8.3)安装与配置

## Jdk安装与配置(略)

## Scala安装与配置
&emsp;&emsp;参考：https://zx950519.github.io/2018/05/16/Scala%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/  

## Spark安装与配置  
&emsp;&emsp;下载地址：https://www.apache.org/dyn/closer.lua/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz  
![](http://ww1.sinaimg.cn/large/005L0VzSgy1frfffou4l1j30qk0a0gn5.jpg)  
&emsp;&emsp;下载后解压到任意位置(例如：E:\spark-2.3.0-bin-hadoop2.7)  
![](http://ww1.sinaimg.cn/large/005L0VzSgy1frffgy1bufj30gw078jrq.jpg)  
&emsp;&emsp;配置环境变量，修改系统环境变量的Path，新增一条：E:\spark-2.3.0-bin-hadoop2.7\bin  
&emsp;&emsp;之后我们在任意位置启动Cmd，输入：spark-shell，进入交互式命令行模式：  
![](http://ww1.sinaimg.cn/large/005L0VzSgy1frffk9j8u0j30ni0kvwex.jpg)  
&emsp;&emsp;如上，可以看到对应的Spark、Scala、Java版本，同时也看到了异常信息，该异常信息是由于Hadoop尚未安装导致的。  

## Hadoop安装与配置
&emsp;&emsp;下载地址：http://hadoop.apache.org/releases.html  
![](http://ww1.sinaimg.cn/large/005L0VzSgy1frffn2mbwmj30y40cywfm.jpg)  
![](http://ww1.sinaimg.cn/large/005L0VzSgy1frffnoklczj30nl07wwfn.jpg)  
&emsp;&emsp;下载后解压到任意位置(例如：E:\hadoop-2.8.3)  
&emsp;&emsp;配置环境变量，修改系统环境变量的Path，新增一条：E:\hadoop-2.8.3\bin；新增系统环境变量HADOOP_HOME，值为：E:\hadoop-2.8.3  
&emsp;&emsp;下载winutils(地址：https://github.com/steveloughran/winutils)，选择和你版本相同的2.8.3,把下载的整个bin目录替换本地的bin目录。  
&emsp;&emsp;再次在Cmd运行spark-shell后：  
![](http://ww1.sinaimg.cn/large/005L0VzSgy1frffsrch4hj30le0b2t8u.jpg)  

## 验证安装成功  
&emsp;&emsp;开启Cmd，运行spark-shell,浏览器输入：http://127.0.0.1:4040/jobs/后回车，看到如下界面即说明安装成功：  
![](http://ww1.sinaimg.cn/large/005L0VzSgy1frffvi8jakj30j70c6t9a.jpg)  


