---
layout:     post
title:      CentOS7生产环境搭建
subtitle:   CentOS7生产环境搭建(VNC;Java;IDE等)
date:       2018-06-05
author:     Alitria
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - CentOS7
    - Shell
---

## 安装图形化界面  

- 1.yum groupinstall GNOME Desktop
- 2.一路yes即可

## VNC搭建  

- 1.打开终端
- 2.yum install tigervnc tigervnc-server(一路yes即可)
- 3.cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service
- 4.vim /etc/systemd/system/vncserver@:1.service(将所有USER包含尖括号改成root)  
- 5.systemctl start vncserver@:1.service;systemctl enable vncserver@:1.service  
- 6.如果上一步遇到了错误(Job for vncserver@:1.service failed because the control process exited with error code. See 
"systemctl status vncserver@:1.service" and "journalctl -xe" for details.)。执行：rm -R /tmp/.X11-unix/后再执行第五步。
- 7.设置密码：vncpasswd，输入两次密码。
- 8.设置防火墙(选做)，第9、10步。
- 9.firewall-cmd --permanent --add-service="vnc-server" --zone="public"
- 10.firewall-cmd --reload
- 11.开启VNC：vncserver(或vncserver :1)
- 12.VNC-Viewer，输入ip:5901即可。

## JDK配置

- 1.解压：tar xzvf jdk-8u144-linux-x64.tar.gz
- 2.vim /etc/profile
- 3.添加如下内容
- 4.export JAVA_HOME=/usr/java/jdk
- 5.export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
- 6.export PATH=$JAVA_HOME/bin:$PATH
- 7.source /etc/profile
- 8.验证：java -version


## IDEA配置

- 1.解压：tar xzvf ideaIU-2018.1.4.tar.gz
- 2.启动：sh idea.sh


## SCALA配置(2.11.12)

- 1.解压：tar -zxf scala-2.11.12.tgz
- 2.vim /etc/profile
- 3.添加如下内容
- 4.export SCALA_HOME=/usr/scala/scala-2.11.6
- 5.export PATH=$PATH:$SCALA_HOME/bin
- 6.source /etc/profile
- 7.验证：scala -version

## SPARK配置(1.6.2)

- 1.解压：tar -xzvf spark-1.6.2-bin-hadoop2.6.tgz
- 2.vim /etc/profile
- 3.添加如下内容
- 4.export SPARK_HOME=/usr/app/spark-1.6.0 
- 5.export PATH=$SPARK_HOME/bin:$PATH
- 6.source /etc/profile
- 7.转到/spark-1.6.2-bin-hadoop2.6/conf/下
- 8.执行：cp spark-env.sh.template spark-env.sh，并按下面修改内容(类似设置JDK),分号代表换行符
- 9.export SCALA_HOME=/mysoftware/scala-2.11.8;export JAVA_HOME=/mysoftware/jdk1.7.0_80;export SPARK_HOME=/home/ZHOU/SPARK;export SPARK_MASTER_IP=你的ip;export SPARK_WORKER_MEMORY=4G
- 10.执行：cp slaves.template slaves,最下面一行设置为：localhost
- 11.执行：cp log4j.properties.template log4j.properties,无需其他设置
- 12.测试Spark是否装好，在bin目录下执行：./run-example SparkPi 10，如果打印出"Pi is roughly 3.141852"，即说明成功。
- 13.启动：/sbin/start-all.sh
- 14.停止：/sbin/stop-all.sh

## HADOOP单机配置(2.6.0)

- 1.解压：tar zxvf hadoop-2.6.0.tar.gz
- 2.修改路径/hadoop-2.7.3/etc/hadoop的文件hadoop-env.sh，将JDK路径加进去(export JAVA_HOME=/home/ZHOU/jdk1.8)
- 3.配置Hadoop环境变量(export HADOOP_HOME=/usr/hadoop/hadoop-2.7.3; export PATH=$PATH:$HADOOP_HOME/bin)
- 4.执行：source /etc/profile
- 5.修改路径/hadoop-2.7.3/etc/hadoop的文件core-site.xml,如下  

![](http://ww1.sinaimg.cn/large/005L0VzSly1fs2o5egqi1j30ei07g0t4.jpg)  

- 6.修改路径/hadoop-2.7.3/etc/hadoop的文件hdfs-site.xml,如下  

![](http://ww1.sinaimg.cn/large/005L0VzSly1fs2o7l4vvtj30k708swf2.jpg)  

- 7.配置完成后，执行初始化：./bin/hdfs namenode -format，打印出的部分信息如下，其中这个127.0.0.1报的错我目前没搞懂啥意思，但是并不影响HDFS的启动  

```
15/05/13 08:50:15 INFO namenode.FSImage: Allocated new BlockPoolId: BP-707136192-127.0.1.1-1431532215593
15/05/13 08:50:15 INFO common.Storage: Storage directory /home/hadoop/opt/hadoop-2.6.0/tmp/dfs/name has been successfully formatted.
15/05/13 08:50:16 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
15/05/13 08:50:16 INFO util.ExitUtil: Exiting with status 0
15/05/13 08:50:16 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.1.1
************************************************************/
```  
  
  
- 8.开启HDFS(NameNode&DataNode):sbin/start-dfs.sh  

![](http://ww1.sinaimg.cn/large/005L0VzSgy1fs2odyrlodj309a042jrg.jpg)  

- 9.打开浏览器，输入：localhost：50070，可看到  

![](http://ww1.sinaimg.cn/large/005L0VzSgy1fs2ohru52ej30rz0cpmxp.jpg)  

- 10.关闭HDFS：sbin/stop-dfs.sh






