---
layout:		post
title:      CentOS7相关配置
subtitle:   CentOS7生产环境搭建
date:       2017-06-05
author:     Alitria
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - Shell
---

## 安装图形化界面(gnome)  

- 1.命令行输入yum groupinstall GNOME Desktop回车
- 2.遇到选择时,输入yes或y回车即可

## 配置静态IP
&emsp;&emsp;修改配置文件即可  
- vim /etc/sysconfig/network-scripts/ifcfg-eth0(最后这个文件，建议大家自己用ifconfig看一下，每个人机器的情况都不一样)  
![](http://ww1.sinaimg.cn/large/005L0VzSly1fu19apy3sgj30iy0cwwga.jpg)  
&emsp;&emsp;如果是用虚拟机的话额外选桥接模式，如下  
![](http://ww1.sinaimg.cn/large/005L0VzSly1fu19copnh5j30ch06nt98.jpg)  


## VNC搭建  
```
    1.yum install tigervnc tigervnc-server(一路yes即可)
    2.cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service
    3.vim /etc/systemd/system/vncserver@:1.service(将所有USER包含尖括号改成root) 
    4.systemctl start vncserver@:1.service;
    5.上一步可能会报错,解决办法如下：删除/tmp/.X11-unix/ 目录, 执行rm -R /tmp/.X11-unix/
    6.systemctl enable vncserver@:1.service
    7.设置密码：vncpasswd，输入两次密码。
    8.设置防火墙(选做)，第9-10步。
    9.firewall-cmd --permanent --add-service="vnc-server" --zone="public"
    10.firewall-cmd --reload
    11.开启VNC：vncserver(或vncserver :1)
    12.在VNC-Viewer中，输入ip:5901即可。
```

## 删除系统自带的OpenJDK
```
    1.切换到root账户
    2.rqm -qa 管道竖线 grep java
    3.rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64
    4.rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64
    5.rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64
    6.rpm -e --nodeps java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64
```

## JDK配置
```
    1.解压：tar xzvf jdk-8u144-linux-x64.tar.gz
    2.vim /etc/profile
    3.添加如下内容
    4.export JAVA_HOME=/usr/java/jdk
    5.export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
    6.export PATH=$JAVA_HOME/bin:$PATH
    7.source /etc/profile
    8.验证：java -version
```

## IDEA安装与使用
```
    1.解压：tar xzvf ideaIU-2018.1.4.tar.gz
    2.启动：sh idea.sh
```

## SCALA配置(2.11.12)
```
    1.解压：tar -zxf scala-2.11.12.tgz
    2.vim /etc/profile
    3.添加如下内容
    4.export SCALA_HOME=/usr/scala/scala-2.11.6
    5.export PATH=$PATH:$SCALA_HOME/bin
    6.source /etc/profile
    7.验证：scala -version
```

## SPARK配置(1.6.2)
```
    1.解压：tar -xzvf spark-1.6.2-bin-hadoop2.6.tgz
    2.vim /etc/profile
    3.添加如下内容
    4.export SPARK_HOME=/usr/app/spark-1.6.0 
    5.export PATH=$SPARK_HOME/bin:$PATH
    6.source /etc/profile
    7.转到/spark-1.6.2-bin-hadoop2.6/conf/下
    8.执行：cp spark-env.sh.template spark-env.sh，并按下面修改内容(类似设置JDK),分号代表换行符
    9.export SCALA_HOME=/mysoftware/scala-2.11.8;export JAVA_HOME=/mysoftware/jdk1.7.0_80;export SPARK_HOME=/home/ZHOU/SPARK;export SPARK_MASTER_IP=你的ip;export SPARK_WORKER_MEMORY=4G
    10.执行：cp slaves.template slaves,最下面一行设置为：localhost
    11.执行：cp log4j.properties.template log4j.properties,无需其他设置
    12.测试Spark是否装好，在bin目录下执行：./run-example SparkPi 10，如果打印出"Pi is roughly 3.141852"，即说明成功。
    13.启动：/sbin/start-all.sh
    14.停止：/sbin/stop-all.sh
```

## HADOOP单机配置(2.6.0)
```
    1.解压：tar zxvf hadoop-2.6.0.tar.gz
    2.修改路径/hadoop-2.7.3/etc/hadoop的文件hadoop-env.sh，将JDK路径加进去(export JAVA_HOME=/home/ZHOU/jdk1.8)
    3.配置Hadoop环境变量(export HADOOP_HOME=/usr/hadoop/hadoop-2.7.3; export PATH=$PATH:$HADOOP_HOME/bin)
    4.执行：source /etc/profile
    5.修改路径/hadoop-2.7.3/etc/hadoop的文件core-site.xml,如下  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1fs2o5egqi1j30ei07g0t4.jpg)  
```
6.修改路径/hadoop-2.7.3/etc/hadoop的文件hdfs-site.xml,如下  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1fs2o7l4vvtj30k708swf2.jpg)  
```
    7.配置完成后，执行初始化：./bin/hdfs namenode -format，打印出的部分信息如下，其中这个127.0.0.1报的错我目前没搞懂啥意思，但是并不影响HDFS的启动
    15/05/13 08:50:15 INFO namenode.FSImage: Allocated new BlockPoolId: BP-707136192-127.0.1.1-1431532215593
    15/05/13 08:50:15 INFO common.Storage: Storage directory /home/hadoop/opt/hadoop-2.6.0/tmp/dfs/name has been successfully formatted.
    15/05/13 08:50:16 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
    15/05/13 08:50:16 INFO util.ExitUtil: Exiting with status 0
    15/05/13 08:50:16 INFO namenode.NameNode: SHUTDOWN_MSG: 
    /************************************************************
    SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.1.1
    ************************************************************/
    8.开启HDFS(NameNode&DataNode):sbin/start-dfs.sh  
``` 
![](http://ww1.sinaimg.cn/large/005L0VzSgy1fs2odyrlodj309a042jrg.jpg)  
```
    9.打开浏览器，输入：localhost：50070，可看到  
```
![](http://ww1.sinaimg.cn/large/005L0VzSgy1fs2ohru52ej30rz0cpmxp.jpg)  
```
    10.关闭HDFS：sbin/stop-dfs.sh
```

## 集群环境下利用KVM分割多机配置静态ip
```
    1. cd /etc/sysconfig/network-scripts
    2. sudo vim ifcfg-eth0
    3. 修改BOOTPROTO=static
    4. 修改ONBOOT=yes
    5. 添加IPADDR=(动态获取的ip)
    6. 添加NETMASK=255.255.255.0
    7. 添加GATEWAY=(宿主网关，在宿主机用netstat -rn查询)
    8. 添加DNS1=114.114.114.114
    9. 重启网络：service network start
```


## 多机间SSH免密登陆
```
    1.对每台主机修改主机名,主节点(master)，从节点(slave01-slave02),分别执行sudo vim /etc/hostname,修改对应主机名
    2.对每台主机添加节点ip以及集群内所有的主机名:sudo vim /etc/hosts 例如(10.1.18.1 master\n 10.1.18.2 slaver01 \n 10.1.18.3 slaver02)  
    3.对每台主机修改sshd配置文件：sudo vim /etc/ssh/sshd_config 将如下点亮(RSAAuthentication yes;PubkeyAuthentication yes;AuthorizedKeysFile      .ssh/authorized_keys)后重启ssh服务：service ssh restart  
    4.对每台机器生成密钥：ssh-keygen -t rsa并敲击数次回车
    5.将所有slave的密钥(xxx.pub)汇总到master，利用:cat xxx.pub >> authorized_keys 将各个节点公钥打入该文件  
    6.利用scp命令分发authorized_keys文件到各个slave节点  
    7.在所有机器上授权：sudo chmod 700 ~/.ssh; sudo chmod 644 ~/.ssh/authorized_keys; sudo chmod 644 ~/.ssh/known_hosts  
    8.测试&通过  
```


## 多机间免密登陆故障处理
```
    1.WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!本机ip:10.1.18.100,欲连接的ip:10.1.18.124,修改本机ip路径下/.ssh的文件konwn_hosts,将与欲连接的ip相关的内容删掉，重新ssh连接即可。
```

## HADOOP完全分布式配置(2.6.0)
```
    1.登录root账户(su root);将压缩包上传至服务器的/usr下;并解压(tar xzvf hadoop2.6.0.......)  
    2.重命名(mv hadoop2.6.0....... hadoop2.6.0); 授权(chown -R hadoop:hadoop hadoop2.6.0)  
    3.添加环境变量(vim /etc/profile)  
        export HADOOP_HOME=/usr/hadoop2.6.0
        export PATH=$PATH:$HADOOP_HOME/bin

    4.配置Hadoop文件  
    4.1./etc/hadoop/hadoop-env.sh  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1am5snfkj308c01e0sj.jpg)  
```
    4.2./etc/hadoop/yarn-env.sh  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1an9ujvhj308x032glh.jpg)  
```
    4.3./etc/hadoop/slaves  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1annl330j303x020dfl.jpg)  
```
    4.4./etc/hadoop/core-site.xml  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1aodfwuoj30eg08cmx9.jpg)  
```
    4.5./etc/hadoop/hdfs-site.xml  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1aop7jz5j30ed08eglq.jpg)
```
    4.6./etc/hadoop/mapred-site.xml 
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1apg4hm3j30ei06o0ss.jpg)  
```
    4.7./etc/hadoop/yarn-site.xml  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1aqpu307j30io0fy758.jpg)
```
    5.格式化namenode(hdfs namenode -format)ps:主节点机器重启后可能需要重新格式化namenode  
    6.启动:start-all.sh;start-dfs.sh;start-yarn.sh  
    7.结果查询，在各个机器上使用jps命令即可
    8.结果截图  
    8.1.master:  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1b3ib1hmj305v032744.jpg)  
```
    8.2.slaver0x：
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ft1b3v2y7jj305y02j3yb.jpg)  
```
&emsp;&emsp;8.3.打开火狐浏览器，输入:master:50070;master:8088;slaves:8042 
```

## Spark完全分布式配置(1.6.2)
```
    1.首先关闭各个机器的防火墙，最好是开机禁用firewall(systemctl stop firewalld.service #停止firewall; systemctl disable firewalld.service #禁止firewall开机启动)  
    2.在各台机器上先配置Scala环境(参考前面单机即可)  
    3.在各台机器上解压缩(tar -zxvf spark-xxx.tgz)  
    4.在各台机器上改名(mv spark-xxx.tgz spark1.6.2)  
    5.在各台机器上配环境变量  
        vim /etc/profile
        export SPARK_HOME=/usr/spark1.6.2
        export PATH=$PATH:$SPARK_HOME/bin
    6.在各台机器上修改conf/spark-env.sh, 如下  
        export JAVA_HOME=/usr/java/jdk1.8.0_141
        export SCALA_HOME=/usr/scala-2.11.7
        export HADOOP_HOME=/opt/hadoop-2.6.5
        export HADOOP_CONF_DIR=/usr/hadoop2.6.0/etc/hadoop
        export SPARK_MASTER_IP=10.1.18.125
        export SPARK_MASTER_PORT=7077
        export SPARK_MASTER_HOST=10.1.18.125
        export SPARK_WORKER_MEMORY=2g
        export SPARK_WORKER_CORES=2
        export SPARK_WORKER_INSTANCES=1
    PS:master_ip必须填真实ip，不能用master代替  
    7.在各台机器上修改conf/slaves, 如下 
        salver01
        slaver02
        slaver03
    8.启动Spark(必须cd到/spark1.6.0/sbin目录下执行sh ./start-all.sh)  
    9.验证安装成果(各个机器上jps一下; 在浏览器上输入master:8080回车查看)  
```

## Spark完全分布式提交任务流程
```
    1.使用IDEA写代码，打包后使用/bin/spark-submit提交，其他参数后续将会解释  
    2.在IDEA中用sbt构建项目  
        name := "sr"
        version := "0.1"
        scalaVersion := "2.11.6"
        libraryDependencies += "org.apache.spark" %% "spark-core" % "2.1.0"
        libraryDependencies += "org.apache.spark" %% "spark-mllib" % "1.5.1"
        libraryDependencies += "org.apache.spark" %% "spark-streaming" % "1.5.1"
        libraryDependencies  ++= Seq(
            // other dependencies here
            "org.scalanlp" %% "breeze" % "0.12",
            // native libraries are not included by default. add this if you want them (as of 0.7)
            // native libraries greatly improve performance, but increase jar sizes.
            // It also packages various blas implementations, which have licenses that may or may not
            // be compatible with the Apache License. No GPL code, as best I know.
            "org.scalanlp" %% "breeze-natives" % "0.12",
            // the visualization library is distributed separately as well.
            // It depends on LGPL code.
            "org.scalanlp" %% "breeze-viz" % "0.12"
        )
        resolvers ++= Seq(
            // other resolvers here
            // if you want to use snapshot builds (currently 0.12-SNAPSHOT), use this.
            "Sonatype Snapshots" at "https://oss.sonatype.org/content/repositories/snapshots/",
            "Sonatype Releases" at "https://oss.sonatype.org/content/repositories/releases/"
        )

    3.然后编写测试代码  
        import org.apache.spark.{SparkConf, SparkContext}
        object WordCount {
            def main(args: Array[String]) {
                val conf = new SparkConf().setAppName("wordcount")
                val sc = new SparkContext(conf)
                // 自备数据集，反正是词频统计，自己随便造一个吧
                // 这个路径是hdfs的路径，根据自己实际情况设定
                val input = sc.textFile("/input/bigfile.txt")
                val lines = input.flatMap(line => (line.split(" ")))
                val count = lines.map(word => (word, 1)).reduceByKey { case (x, y) => x + y }
                val output=count.saveAsTextFile("/input/bigfileres.txt")
            }
        }

    4.然后执行打包操作,具体如下:File -> Project Structure -> Aritifacts -> 点击+号 ->jar -> 第二个 -> 指定Module和MainClass -> JAR files from libraries 选择第二个 ->点击ok;主题栏点击Build -> Build Aritifacts - Build;在工程目下out目录中生成相应jar包即打包成功,在下图中，当我们看到sr.jar即说明搞定，我们这个项目的名字就叫sr(shit，我想抽ssr啊)  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ftky6ijqz9j307f092q31.jpg)  
```
    5.先上传相关代码所需输入文件，贴几个常见的hdfs命令  
    - 1.查看hdfs的某目录:hdfs dfs -ls /目录名  
    - 2.新建目录:hdfs dfs -mkdir /目录名  
    - 3.上传文件到hdfs:hdfs dfs -put /文件路径 /目标路径(不带文件名)    
    - 4.下载文件到本地:hdfs dfs -get /文件路径(带文件名)  /目标路径  
    - 5.删除hdfs文件:hadoop fs -rm -r /文件路径 
    6.在spark的目录下执行:"./bin/spark-submit --master spark://master:7077 --class WordCount /home/hadoop/sr.jar"  
    7.说明:参数master指定谁是控制机器;参数Class指定主类以及之前打包的项目位置  
    8.可以在浏览器中查看运行结果(master:8080)  
```
![](http://ww1.sinaimg.cn/large/005L0VzSly1ftl1tk5886j30pe03mgme.jpg)  

## maven安装
``` 
    1.下载压缩包  
    2.解压(tar -zxvf apache........)  
    3.配置环境变量(su root; vim /etc/profile)，如下：  
        export M2_HOME=/usr/maven
        export MAVEN_OPTS="-Xms256m -Xmx512m"
        export PATH=$PATH:$M2_HOME/bin
    4.刷新(source /etc/profile)  
    5.验证(mvn -v)
```

## protobuf安装
```
    1.下载压缩包(wget https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz)  
    2.解压缩并进入文件夹(tar -zxvf protobuf-2.5.0.tar.gz)  
    3.执行(./configure)  
    4.执行(make && make install)  
    5.修改环境变量(export PATH=/home/hadoop/protobuf-2.5.0/bin:$PATH)  
    6.验证(protoc --version), 出现libprotoc 2.5.0 则说明安装成功
```

## Caffe_MPI_Environment
Caffe-MPI在Centos7下的安装
### 目录
- 说明
- 快速安装
- 普通安装 
- 运行demo
- 致谢
#### 说明
&emsp;&emsp;原案传送门:https://github.com/sailorsb/caffe-parallel  
&emsp;&emsp;Caffe-Parallel是一个更快的深度学习框架，它来自BVLC / caffe（主分支）。（https://github.com/BVLC/caffe，更多详情请访问 http://caffe.berkeleyvision.org）。该项目的主要成就是通过MPI实现数据并行。  
&emsp;&emsp;下面的安装过程必要的环境依赖于集群内所有机器可以互相免密ssh，请提前配置好。自动化脚本可以参考:https://github.com/Beckham007/b_keygen 
#### 快速安装
&emsp;&emsp;在快速安装中，我们仅需将已经编译好的各个组件从压缩包中解压，然后配置本地环境即可，在我的环境中的目录结构为:  
```
-home
  |---其他用户
  |---hadoop
        |---其他文件夹
        |---environment
              |---boost(组件)
              |---caffe-parallel-master(主要)
              |---curl(组件)
              |---gflags(组件)
              |---glog(组件)
              |---glog-master(组件)
              |---hdf5(组件)
              |---jsoncpp(组件)
              |---leveldb(组件)
              |---lmdb(组件)
              |---openblas(低版本)
              |---openblas-0.2.20(组件)
              |---opencv-2.4.9(组件)
              |---openmpi-1.6.5(弃用)
              |---protobuf(组件)
              |---snappy(组件)
              |---myenv2profile.txt(环境变量配置文件)
              |---myinjectLib(需要注入的库的集合)
        |---environment.tar.gz
        |---openmpi-1.6.5(组件)
        |---openmpi-1.6.5.tar.gz
```
&emsp;&emsp;在后续的安装中,发现了一个暂时无法解决的问题,因此最新版本安装后的文件目录如下:
```
-home
  |---hadoop
      |---boost(组件)
      |---caffe-parallel-master(主要)
      |---curl(组件)
      |---gflags(组件)
      |---glog(组件)
      |---glog-master(组件)
      |---hdf5(组件)
      |---jsoncpp(组件)
      |---leveldb(组件)
      |---lmdb(组件)
      |---openblas(低版本)
      |---openblas-0.2.20(组件)
      |---opencv-2.4.9(组件)
      |---openmpi-1.6.5(弃用)
      |---protobuf(组件)
      |---snappy(组件)
      |---myenv2profile.txt(注入环境变量的文本)
      |---myinjectLib(需要注入的库的集合)
      |---openmpi-1.6.5(组件)
```
&emsp;&emsp;建议使用NFS系统的读者,直接在home目录下创建hadoop文件夹作为共享目录
- 解压缩包后目录如上
- cd environment后su root登录root账户
- 执行：cat myenv2profile.txt >> /etc/profile将我们预先写好的环境变量(需要根据你自己的环境进行修改)直接进行追加，避免繁琐的手工配置，PS：如果权限不够请写入.bashrc中  
```  
export PATH=$PATH:/home/hadoop/envirnoment/boost_1640/include
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/boost_1640/lib

export PATH=$PATH:/home/hadoop/environment/opencv-2.4.9/include
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/opencv-2.4.9/lib
export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/home/hadoop/environment/opencv-2.4.9/lib/pkgconfig

export PATH=$PATH:/home/hadoop/environment/OpenBLAS/include
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/OpenBLAS/lib

export PATH=$PATH:/home/hadoop/environment/gflags-2.0/include

export PATH=$PATH:/usr/include

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib

export HDF5_DIR=/home/hadoop/environment/hdf5
export PATH=$PATH:/home/hadoop/environment/hdf5/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/hdf5/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/hdf5/share

export PATH=$PATH:/home/hadoop/environment/curl/include
export PATH=$PATH:/home/hadoop/environment/curl/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/curl/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/curl/share

export GFLAGS_ROOT_DIR=/home/hadoop/environment/gflags-2.0
export PATH=$PATH:/home/hadoop/environment/gflags-2.0/include
export PATH=$PATH:/home/hadoop/environment/gflags-2.0/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/gflags-2.0/lib

export GLOG_ROOT_DIR=/home/hadoop/environment/glog
export PATH=$PATH:/home/hadoop/environment/glog/include
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/glog/lib
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/glog/share

export LEVELLDB_ROOT=/home/hadoop/environment/leveldb:$PATH
export PATH=$PATH://home/hadoop/environment/leveldb/include
export LD_LIBRARY_PATH=/home/hadoop/environment/leveldb/lib64:$LD_LIBRARY_PATH

export LMDB__DIR=/home/hadoop/environment/lmdb
export PATH=$PATH:/home/hadoop/environment/lmdb/include
export PATH=$PATH:/home/hadoop/environment/lmdb/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/hadoop/environment/lmdb/lib

export PATH=/home/hadoop/environment/protobuf/include:$PATH
export PATH=/home/hadoop/environment/protobuf/bin:$PATH
export LD_LIBRARY_PATH=/home/hadoop/environment/protobuf/lib:$LD_LIBRARY_PATH

export PATH=/home/hadoop/openmpi-1.6.5/bin:$PATH
export PATH=/home/hadoop/openmpi-1.6.5/include:$PATH
export LD_LIBRARY_PATH=/home/hadoop/openmpi-1.6.5/lib:$LD_LIBRARY_PATH

export LD_LIBRARY_PATH=/home/hadoop/environment/jsoncpp/libs/linux-gcc-4.8.5:$LD_LIBRARY_PATH

```
- cd myinjectLib后执行：cp ./lib* /usr/lib将所有运行时需要的库注入到系统默认的动态链接库  
#### 普通安装
&emsp;&emsp;依赖环境及其版本如下图所示，在各自官网下载即可，手动安装教程请参考度娘或Google。具体细节有待补充：  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ftvg577c5oj30ff0f7wej.jpg)  
#### 编译
&emsp;&emsp;对于BSP与SSP,在新安装环境首次运行时需要安装或修改以下内容：

```
    1.安装gcc/g++/gdb,执行yum install gcc-c++即可
    2.修改项目根路径下的编译配置文件Makefile.config
        修改INCLUDE_DIRS的路径前缀
        修改LIBRARY_DIRS的路径前缀
    3.修改/examples/mnist路径下的超参数文件lenet_solver.prototxt
        修改net的路径值
        修改snapshot_perfix的路径值
    4.修改训练集和测试集的配置文件lenet_train_test.prototxt
        修改data_param下的source路径值,共两个
```
#### 运行Demo
&emsp;&emsp;测试mpi是否安装好:mpirun -n 6 pwd
&emsp;&emsp;单机测试caffe-mpi运行:在/home/hadoop/environment/caffe-parallel-master/examples/mnist目录下；修改machinefile，填写自己机器hostname；在终端里输入 sh ./MyTrainLenet.sh即可；下图是我在一个从节点单机运行测试程序：
![](http://ww1.sinaimg.cn/large/005L0VzSly1ftvfvbf5xfj30iv09owhp.jpg)  
&emsp;&emsp;单机测试caffe-mpi运行:在/home/hadoop/environment/caffe-parallel-master/examples/mnist目录下；修改machinefile，填写参与计算的机器hostname；在终端里输入 sh ./MyTrainLenet.sh即可；下图是我在一个master节点并行运行测试程序：  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ftvfzszvltj30ir06eabo.jpg)  
![](http://ww1.sinaimg.cn/large/005L0VzSly1ftvfzzosegj30ix05w0ud.jpg)  
#### 致谢
&emsp;&emsp;感谢范禹辰同学的热心帮助！

## JB全家桶账户(已于2018/11/23失效)
&emsp;&emsp;账号:Xiang_Zhou2018;密码:Aa950519  

## NFS网络文件系统
#### 服务端配置  
```
    1.安装命令:yum install -y nfs-utils rpcbind
    2.修改配置文件:vim /etc/exports;新增一行:/home/hadoop/share 10.1.18.0/24(rw,async,insecure,anonuid=0,anongid=0,no_root_squash)或者(rw,anonuid=0,anongid=0,all_squash,sync)  
        /home/hadoop/share 是服务器端要共享出去的文件路径
        10.1.18.0/24 是网段，代表10.1.18.0-10.1.18.255都可以访问
        rw：read-write，可读写；
        ro：read-only，只读；
        sync：文件同时写入硬盘和内存；
        async：文件暂存于内存，而不是直接写入内存；
        no_root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，也拥有root权限。显然开启这项是不安全的。
        root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，拥有匿名用户权限，通常他将使用nobody或nfsnobody身份；
        all_squash：不论NFS客户端连接服务端时使用什么用户，对服务端分享的目录来说都是拥有匿名用户权限；
        anonuid：匿名用户的UID值
        anongid：匿名用户的GID值。备注：其中anonuid=1000,anongid=1000,为此目录用户web的ID号,达到连接NFS用户权限一致。
        defaults 使用默认的选项。默认选项为rw、suid、dev、exec、auto nouser与async。
        atime 每次存取都更新inode的存取时间，默认设置，取消选项为noatime。
        noatime 每次存取时不更新inode的存取时间。
        dev 可读文件系统上的字符或块设备，取消选项为nodev。
        nodev 不读文件系统上的字符或块设备。
        exec 可执行二进制文件，取消选项为noexec。
        noexec 无法执行二进制文件。
        auto 必须在/etc/fstab文件中指定此选项。执行-a参数时，会加载设置为auto的设备，取消选取为noauto。
        noauto 无法使用auto加载。
        suid 启动set-user-identifier设置用户ID与set-group-identifer设置组ID设置位，取消选项为nosuid。
        nosuid 关闭set-user-identifier设置用户ID与set-group-identifer设置组ID设置位。
        user 普通用户可以执行加载操作。
        nouser 普通用户无法执行加载操作，默认设置。
        remount 重新加载设备。通常用于改变设备的设置状态。
        rsize 读取数据缓冲大小，默认设置1024。–影响性能
        wsize 写入数据缓冲大小，默认设置1024。
        fg 以前台形式执行挂载操作，默认设置。在挂载失败时会影响正常操作响应。
        bg 以后台形式执行挂载操作。
        hard 硬式挂载，默认设置。如果与服务器通讯失败，让试图访问它的操作被阻塞，直到服务器恢复为止。
        soft 软式挂载。服务器通讯失败，让试图访问它的操作失败，返回一条出错消息。这项功能对于避免进程挂在无关紧要的安装操作上来说非常有用。
        retrans=n 指定在以软方式安装的文件系统上，在返回一条出错消息之前重复发出请求的次数。
        nointr 不允许用户中断，默认设置。
        intr 允许用户中断被阻塞的操作并且让它们返回一条出错消息。
        timeo=n 设置请求的超时时间以十分之一秒为单位。
        tcp 传输默认使用udp,可能出现不稳定，使用proto=tcp更改传输协议。客户端参考mountproto=netid
    3.使配置生效:exportfs -rv  
    4.启动并设置开机自动启动:systemctl enable rpcbind;systemctl start rpcbind;systemctl enable nfs-server;systemctl start nfs-server  
    5.查看启动情况:rpcinfo -p
    6.对共享文件夹授权:chomd 777 -R /home/hadoop/share
```
#### 客户端配置
```
    1.安装命令:yum install -y nfs-utils rpcbind
    2.设置开机自动启动:chkconfig nfs on; chkconfig rpcbind on
    3.启动服务:service rpcbind start; service nfs start
    4.创建挂载点前可能需要关闭防火墙：systemctl stop firewalld.service;systemctl disable firewalld.service
    5.创建挂载点:mount -t nfs server_ip:/home/hadoop/share /home/hadoop/share //注释-服务器地址:/服务器下共享文件夹的路径 本地的共享文件夹路径
    6.查看挂载目录:df -h
    7.卸载挂载目录:umount /home/hadoop/share
    8.开机自动挂载:sudo vim /etc/fstab; 添加一行:server_ip:/home/hadoop/share /home/hadoop/share nfs rw,tcp,intr 0 1
```
#### 故障处理
```
    1.重启服务器端：service nfs reload  
    2.重启服务器端：service nfs restart  
```

## NTP时间校准
#### 服务器端设置
```
    1.安装/更新ntp:yum install -y ntp
    2.先校准时间:ntpdate cn.pool.ntp.org
    3.更改配置:sudo vim /etc/ntp.conf
        #server 0.centos.pool.ntp.org iburst
        #server 1.centos.pool.ntp.org iburst
        #server 2.centos.pool.ntp.org iburst
        #server 3.centos.pool.ntp.org iburst
        server 0.cn.pool.ntp.org iburst
        server 1.cn.pool.ntp.org iburst
        server 2.cn.pool.ntp.org iburst
        server 3.cn.pool.ntp.org iburst
        server 127.127.1.0   
        fudge  127.127.1.0 stratum 10
    4.启动/重启ntp:service ntpd start(restart)
    5.查看ntp情况:ntpq -p
    6.设置开机启动:chkconfig ntpd on
```
#### 客户端设置
```
    1.安装/更新ntp:yum install -y ntp
    2.先校准时间:ntpdate master_ip
    3.更改配置:sudo vim /etc/ntp.conf
        #server 0.centos.pool.ntp.org iburst
        #server 1.centos.pool.ntp.org iburst
        #server 2.centos.pool.ntp.org iburst
        #server 3.centos.pool.ntp.org iburst
        server master_ip iburst
    4.启动/重启ntp:service ntpd start(restart)
    5.查看ntp情况:ntpq -p
    6.设置开机启动:chkconfig ntpd on
```

#### 查询各个机器时间的脚本
&emsp;&emsp;执行前可能需要执行:yum -y install expect  

```
#!/bin/bash
USER="root"
PASS="1"

all_hosts="mdw sdw01 sdw02 sdw03 sdw04"
for element in $all_hosts
do
  HOST=$element
  EX_RUN=$(expect -c "
  spawn ssh $USER@$HOST date \+\%Y\%m\%d\-\%H\%M\%S
  expect \"password:\"
  send \"$PASS\r\"
  interact
  ")
  echo "$EX_RUN" &
done
```
