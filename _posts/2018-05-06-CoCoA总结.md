---
layout:     post
title:      CoCoA论文+代码实操
subtitle:   System-Aware Optimization for Machine Learning at Scale
date:       2018-05-06
author:     Alitria
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - CoCoA
    - Paper
    - Code
---

## 题目——System-Aware Optimization for Machine Learning at Scale
链接：https://escholarship.org/uc/item/20n1k4q8  
作者：Virginia Smith  
时间：August 9, 2017  

## 论文

#### Abstract
&emsp;&emsp;New computing systems have emerged in response to the increasing size and complexity
of modern datasets. For best performance, machine learning methods must be designed to
closely align with the underlying properties of these systems.
In this thesis, we illustrate the impact of system-aware machine learning through the
lens of optimization, a crucial component in formulating and solving most machine learning
problems. Classically, the performance of an optimization method is measured in terms of
accuracy (i.e., does it realize the correct machine learning model? ) and convergence rate
(after how many iterations? ). In modern computing regimes, however, it becomes critical to
additionally consider a number of systems-related aspects for best overall performance. These
aspects can range from low-level details, such as data structures or machine specifications,
to higher-level concepts, such as the tradeoff between communication and computation.
We propose a general optimization framework for machine learning, CoCoA, that gives
careful consideration to systems parameters, often incorporating them directly into the
method and theory. We illustrate the impact of CoCoA in two popular distributed regimes:
the traditional cluster-computing environment, and the increasingly common setting of ondevice
(federated) learning. Our results indicate that by marrying systems-level parameters
and optimization techniques, we can achieve orders-of-magnitude speedups for solving modern
machine learning problems at scale. We corroborate these empirical results by providing
theoretical guarantees that expose systems parameters to give further insight into empirical
performance.  

&emsp;&emsp;由于现代数据集不断增加的大小以及复杂性，新的计算系统应运而生。为了最佳性能，机器学习必须被设计地与系统底层
属性紧密相连。在本文中，我们通过镜像优化(一个解释和解决大多数机器学习问题的重要组件)阐明了系统感知机器学习的影响。具有
典型意义的是，一种优化方法的性能是由其精度衡量(例如，它是否实现了正确的机器学习模型)以及收敛率(经历的多少次迭代)衡量的。
然而在现代计算机体系中，为了整体最佳性能，选择一系列系统相关的方面就变得至关重要。这些方面可以从低级细节，例如数据
结构或机器规格，变化到高级层次，例如通信和计算的平衡。我们提出了一种对机器学习优化一般性优化框架，CoCoA，它仔细考虑了系统
参数，通常将它们直接纳入方法和理论中。我们将在两种流行的分布式系统中阐明CoCoA的影响：传统的集群环境以及越来越流行的ondevice
学习(Google的Federated Learning)。我们的结果表明，通过结合系统级参数和机器进行优化，我们可以实现数量级的加速来解决现代
机器学习的规模问题。我们证实这些经验结果提供理论保证并暴露系统参数，以进一步观察经验性能。
